{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce9c21dd-244e-4934-b47d-371206a1da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Database\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db8cd91-ead1-4fe2-ab38-af5c571969b6",
   "metadata": {},
   "source": [
    "### Goal: Transfer all data on sales_data folder into Postgresqldatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6af2e0-2d06-476f-98a8-72bdcb0de19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files on the source file\n",
    "def get_file(data_path):\n",
    "    files = [file for file in os.listdir(data_path) if file.endswith('.csv')]\n",
    "    return files\n",
    "\n",
    "\n",
    "# transfer files into specified directory\n",
    "def transfer_files(main_path, data_dir):\n",
    "    # Create directory for the datasets\n",
    "    try:\n",
    "        mkdir = f'mkdir {data_dir}'\n",
    "        os.system(mkdir)\n",
    "    except:\n",
    "        print(\"already exist\")\n",
    "        \n",
    "    files = get_file(data_dir)\n",
    "    \n",
    "    for file in files:\n",
    "        try:\n",
    "            mv_file = shutil.move(main_path+'/'+file, data_dir)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return files\n",
    "\n",
    "\n",
    "# create dataframe\n",
    "def create_df(files, data_dir):\n",
    "    df = {}\n",
    "    data_path = os.getcwd()+'/'+data_dir+'/'\n",
    "    for file in files:\n",
    "        df[file] = pd.read_csv(data_path+file)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Clean and Transform data\n",
    "def transform_data(data):\n",
    "    #columns to convert dtypes\n",
    "    columns_num = ['Order ID', 'Quantity Ordered','Price Each']\n",
    "    columns_date = ['Order Date']\n",
    "    \n",
    "    data.drop_duplicates(inplace=True, ignore_index = True)\n",
    "    \n",
    "    for col in columns_num:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    \n",
    "    for col in columns_date:\n",
    "        data[col] = pd.to_datetime(data[col], format='%m/%d/%y %H:%M', errors='coerce')\n",
    "    \n",
    "            \n",
    "    data.dropna(inplace=True, ignore_index = True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15f67975-ddd6-4f17-bcee-a916a8e64051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales_April_2019 was successfully created!\n",
      "Values successfully added!\n",
      "Sales_August_2019 was successfully created!\n",
      "Values successfully added!\n",
      "Sales_December_2019 was successfully created!\n",
      "Values successfully added!\n",
      "Sales_February_2019 was successfully created!\n",
      "Values successfully added!\n",
      "Sales_January_2019 was successfully created!\n",
      "Values successfully added!\n",
      "Sales_July_2019 was successfully created!\n",
      "Values successfully added!\n",
      "Sales_June_2019 was successfully created!\n",
      "Values successfully added!\n",
      "Sales_March_2019 was successfully created!\n",
      "Values successfully added!\n",
      "Sales_May_2019 was successfully created!\n",
      "Values successfully added!\n",
      "Sales_November_2019 was successfully created!\n",
      "Values successfully added!\n",
      "Sales_October_2019 was successfully created!\n",
      "Values successfully added!\n",
      "Sales_September_2019 was successfully created!\n",
      "Values successfully added!\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_path = '/Users/chano/Programming files'\n",
    "    data_dir = '2019_sales_data'\n",
    "\n",
    "    files = transfer_files(main_path, data_dir)\n",
    "    df = create_df(files,data_dir)\n",
    "    \n",
    "    columns_int = ['Order ID', 'Quantity Ordered']\n",
    "    \n",
    "    for file in files:\n",
    "        errors = []\n",
    "        data = df[file]\n",
    "\n",
    "        # removing the .csv on the filename\n",
    "        table_name = '{0}'.format(file.split('.')[0]).replace(' ','_')\n",
    "\n",
    "        \n",
    "        clean_data = transform_data(data)\n",
    "        for col in columns_int:\n",
    "            clean_data[col] = clean_data[col].apply(np.int64)\n",
    "        \n",
    "        # Clean columns\n",
    "        data.columns = [col.replace(' ','_') for col in clean_data.columns]  \n",
    "        \n",
    "        # replacement dictionary, it maps the pandas dtypes to sql dtypes\n",
    "        replacements = {\n",
    "        'object': 'varchar',\n",
    "        'int64' : 'int',\n",
    "        'float64': 'float',\n",
    "        'datetime64[ns]':'timestamp'\n",
    "        }\n",
    "\n",
    "        # columns table constraint\n",
    "        col_sql = \" , \".join('{} {}'.format(n ,d) for (n, d) in zip(data.columns, data.dtypes.replace(replacements)))\n",
    "        \n",
    "        # Connect to database\n",
    "        conn = psycopg2.connect(\n",
    "           database=\"sales_data_2019\", \n",
    "            user='postgres', \n",
    "            password='XXXXXXX', \n",
    "            host='XXXXXXX', \n",
    "            port= 'XXXXXX'\n",
    "            )\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        # Adding tables to database\n",
    "        cur.execute(f\"\"\"DROP TABLE IF EXISTS {table_name}\"\"\")\n",
    "        cur.execute(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {table_name} ({col_sql});\n",
    "        \"\"\")\n",
    "        \n",
    "        # Saving dataframe to csv\n",
    "        data.to_csv(file, header=data.columns, index=False)\n",
    "        \n",
    "        #Open csv and store into memory\n",
    "        my_file = open(file)\n",
    "        print(f\"{table_name} was successfully created!\")\n",
    "        \n",
    "        # upload csv to database \n",
    "        # Need to review\n",
    "        \n",
    "        sql_statement = f\"\"\"\n",
    "            COPY {table_name} FROM STDIN WITH\n",
    "                CSV\n",
    "                HEADER\n",
    "                DELIMITER AS ','\n",
    "        \"\"\"\n",
    "        \n",
    "        cur.copy_expert(sql=sql_statement, file=my_file)\n",
    "        print(\"Values successfully added!\")\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5114ba58-8881-4cfa-9946-2d7e6a1979a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4904486-aee7-4177-aa73-2283751fb8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2762a00d-999c-468a-9bd4-30c1a06203a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a9ff0-ad05-40c4-b058-9d6a2a6ee2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6dde47-f592-4d0b-9558-0d1591d88a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f57c349-db5d-44be-a343-6c54b204b20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0499b3-c343-404b-a780-6fd259384e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e643f-5247-4a40-b1e4-d87fe6a80e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073ee965-0c19-4812-9419-f032652aa606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
